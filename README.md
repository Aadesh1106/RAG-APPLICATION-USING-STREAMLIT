#  RAG Application using Streamlit

This project demonstrates a simple yet powerful **Retrieval-Augmented Generation (RAG)** application built with **Python**, **Streamlit**, and **LLMs**. It allows users to ask questions against a custom document knowledge base and receive accurate answers by combining document retrieval and generative AI.

---

##  What is RAG?

**Retrieval-Augmented Generation** is a technique that enhances language models by retrieving relevant context from a document store before generating responses. This overcomes the limitations of static LLM memory and enables domain-specific Q&A.

---

##  Features

- Upload custom documents (PDF, TXT, etc.)
- Create embeddings using vector databases (e.g., FAISS)
- Ask natural language questions about the content
- Answers generated with LLMs using retrieved chunks as context
- Clean, interactive **Streamlit UI**

---

##  Tech Stack

- **Python**
- **Streamlit** – for web app UI
- **LangChain / Hugging Face / OpenAI / LlamaCpp** – (depending on your backend setup)
- **FAISS / Chroma / Pinecone** – for vector search
- **LLMs** – OpenAI, LLaMA, or others
- **PDF/Text Parser** – for loading documents

---

##  Setup Instructions

### 1. Clone the Repository

```bash
git clone https://github.com/Aadesh1106/RAG-APPLICATION-USING-STREAMLIT.git
cd RAG-APPLICATION-USING-STREAMLIT
