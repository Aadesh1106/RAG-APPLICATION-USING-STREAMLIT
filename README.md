# ğŸ§ ğŸ” RAG Application using Streamlit

This project demonstrates a simple yet powerful **Retrieval-Augmented Generation (RAG)** application built with **Python**, **Streamlit**, and **LLMs**. It allows users to ask questions against a custom document knowledge base and receive accurate answers by combining document retrieval and generative AI.

---

## ğŸš€ What is RAG?

**Retrieval-Augmented Generation** is a technique that enhances language models by retrieving relevant context from a document store before generating responses. This overcomes the limitations of static LLM memory and enables domain-specific Q&A.

---

## âœ¨ Features

- Upload custom documents (PDF, TXT, etc.)
- Create embeddings using vector databases (e.g., FAISS)
- Ask natural language questions about the content
- Answers generated with LLMs using retrieved chunks as context
- Clean, interactive **Streamlit UI**

---

## ğŸ§° Tech Stack

- **Python**
- **Streamlit** â€“ for web app UI
- **LangChain / Hugging Face / OpenAI / LlamaCpp** â€“ (depending on your backend setup)
- **FAISS / Chroma / Pinecone** â€“ for vector search
- **LLMs** â€“ OpenAI, LLaMA, or others
- **PDF/Text Parser** â€“ for loading documents

---

## ğŸ“¦ Setup Instructions

### 1. Clone the Repository

```bash
git clone https://github.com/Aadesh1106/RAG-APPLICATION-USING-STREAMLIT.git
cd RAG-APPLICATION-USING-STREAMLIT
